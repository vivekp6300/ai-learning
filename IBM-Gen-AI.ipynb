{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f87b06f-d89f-4019-8c1b-1b01488c5b3f",
   "metadata": {},
   "source": [
    "# IBM RAG and Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb99bd-0b82-4701-b4f8-7e6347495018",
   "metadata": {},
   "source": [
    "## Course 3 - Vector Databases for RAG: An Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a88fdd-06d2-4a5f-b421-e4bad5ab01c2",
   "metadata": {},
   "source": [
    "### Module 1 - Introduction to Vector Databases and Chroma DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c60364-091b-41ce-a487-2b52310f5049",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Lecture 1 - Vector Database Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec999fe-cd3a-4a5d-836a-640b7e470e40",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- Vector DBs can be used to group items, classify items and suggest relationships among items\n",
    "- Vector DBs can be used\n",
    "    - to store complex data types (social likes, geospatial data, genomic data etc)\n",
    "      <img src='images/200754.008_Vector-DB-reading-image1.png' width=600/>\n",
    "    - perform similarity searches\n",
    "    - for diverse domains like biology, healthcare, e-commerce, social media and traffic planning)\n",
    "    - to support machine learning\n",
    "- Traditional DBs store data as tables, Vector DBs store data as high dimensional vectors with size and direction. Each dimension relates to different attributes. For e.g. a book can be stored in vector DB as [1, 300, 2024, 4.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6adddb-c3ed-4712-b524-ddd3015354c8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Lecture 2 - Traditional vs Vector Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa3ee4-90d8-4727-a220-a6dcd5ed719f",
   "metadata": {},
   "source": [
    "|Function|Traditional databases|Vector databases|\n",
    "|------|------|------|\n",
    "|Data Representation|Traditional databases organize data in a structured format using tables, rows, and columns, ideal for relational data|Vector databases represent data as multi-dimensional vectors, efficiently encoding complex and unstructured data like images, text, and sensor data.|\n",
    "|Data Search and Retrieval|SQL queries are suited for traditional databases with structured data.|Vector databases specialize in similarity searches and retrieving vectorized data, facilitating tasks like image retrieval, recommendation systems, and anomaly detection.|\n",
    "|Indexing|Traditional databases employ indexing methods like B-trees for efficient data retrieval.|Vector databases use indexing structures like metric trees and hashing suited for high-dimensional spaces, enhancing nearest-neighbor searches and similarity assessments.|\n",
    "|Scalability|Scaling traditional databases can be challenging, often requiring resource augmentation or data sharding.|Vector databases are designed for scalability, especially in handling large datasets and similarity searches, using distributed architectures for horizontal scaling.|\n",
    "|Applications|Traditional databases are pivotal in business applications and transactional systems where structured data is processed.|Vector databases shine in analyzing vast datasets, supporting fields like scientific research, natural language processing, and multimedia analysis.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef86a4-8d7f-43b9-8ccf-a3be223d7c0d",
   "metadata": {},
   "source": [
    "#### Lecture 3 - Vector Database Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc7c0d-55c1-4796-81ba-e6a6b330cc56",
   "metadata": {},
   "source": [
    "- **In-memory** Vector DBs e.g. *RedisAI, Torchserve* store vectors in RAM hence fast but limited in size\n",
    "- **Disk-Based** Vector DBs e.g. *Annoy, Milvus, ScaNN* store vectors on disk, use compression and indexing and are suitable for large datasets\n",
    "- **Distributed** Vector DBs e.g. *FAISS, ElasticSearch+, Dask-ML* spread data across multiple nodes/servers hence great for horizotnal scaling and fault tolerance making them suitable for large datasets with fast retrieval\n",
    "- **Graph Based** Vector DBs e.g. *Neo4J, Amazon Neptune, TigerGraph* model data as a graph with nodes and edges representing attributes. They are great at capturing complex relationships and graph analytics\n",
    "- **Time Series** Vector DBs e.g. *InfluxDB, TimescaleDB, Prometheus* represent data collected over time as vectors and are good for identifying temporal patterns and anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd5208-01b6-4309-a86d-f63bc3402f46",
   "metadata": {},
   "source": [
    "Vector DBs can also be classified as dedicated vector DBs or DBs that support vector search\n",
    "\n",
    "**Dedicated Vector DBs**\n",
    "- use unique data structures like reverse indexes, product quantization and Locality-sensitive Hashing (LSH)\n",
    "- support vector operations like similarity search, nearest neighbour search and distance calculations\n",
    "- provide scaleability through clustering or distributed nodes\n",
    "- deliver speed through optimized algorithms and data structures\n",
    "- are customisable by changing parameters of indexing and searching as per application needs\n",
    "- Examples are FAISS, Annoy and Milvus\n",
    "\n",
    "**Databases that support Vector Search**\n",
    "- are regular DBs or data processing frameworks that have tools and addons to allow users to do vector search and other queries\n",
    "- Store data as part of their data model as BLOBs, Arrays or UDTs.\n",
    "- Allow standard and custom indexing to organise data\n",
    "- Have add-on libraries and plugins to support vector operations\n",
    "- Not as optimized or fast as dedicated vector DBs\n",
    "- Examples are SingleStore (works with watsonx.ai), ElasticSearch, PostgreSQL, MySQL, RedisAI, Apache MongoDB and Apache Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa0423-de48-431a-ba81-78746839c074",
   "metadata": {},
   "source": [
    "#### Lecture 4 - Applications of Vector DBs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc13dd-75c6-42c6-b68b-f14ba5e37eee",
   "metadata": {},
   "source": [
    "1. **Image and Video Analysis**\n",
    "|Task|Capability|Uses|\n",
    "|------|------|------|\n",
    "|Feature Extraction & Representation|Store High-Dimensional Feature Vectors|Displays aspects of images, such as color histograms, texture descriptions or deep learning embeddings|\n",
    "|Similarity Searches|Store Feature Vectors|Locate images, Summarize videos, and suggest images and videos based on content|\n",
    "|Process Real-time data|Provide horizontal scaling for real-time storage|Perform video surveillance, object recognition, and live event analysis|\n",
    "\n",
    "2. **Recommendation Systems**\n",
    "|Task|Capability|Uses|\n",
    "|------|------|------|\n",
    "|Embedding Storage and Nearest Neighbour Search|Incorporate embeddings or numerical representations of items or entities generated by a recommendation system|Access the vector's likes and traits, Locate the vector's closest neighbours for improved personalized suggestions|\n",
    "|Deliver performance improvement and scalability|Provide scalability to handle additional searches and vectors. Improve query processing and indexing structure|Deliver fast, scalabale recommendation services for large numbers of concurrent users|\n",
    "|Provide cross-domain suggestions|Store embeddings and carry out cross-domain suggestions|Enhance the completeness of recommendation systems|\n",
    "\n",
    "3. **Geospatial analysis and location-based services**\n",
    "|Task|Capability|Uses|\n",
    "|------|------|------|\n",
    "|Efficiently store and index data| * Use indexing methods like R-tree or quad tree * Store geospatial data like addresses, polygons, GPS locations | Deliver spatial queries like closeness searches, range queries and spatial joins, for GPS information and other mapping needs|\n",
    "|Provide location-based suggestions|Combine geospatial data with user preferences and location|Deliver recommendations for nearby events, services and places of interest|\n",
    "|Deliver realtime geospatial analytics|*Process streaming data in real-time * Groups items together spatially * Recognizes spatial patterns|Power apps like tracking vehicles, managing fleets, dynamic routing, finding hotspots|\n",
    "\n",
    "4. **Marketing and social media insights**\n",
    "\n",
    "|Task|Capability|Uses|\n",
    "|------|------|------|\n",
    "|Provide distributed storage and parallel processing for horizontal scalability|Spread data and queries across multiple nodes or groups|Process big data and handle simultaneous queries such as SEO calculations|\n",
    "|Reduce latency and boost overall speed|Use optimized caching and query execution plans|Obtain trending analytics faster|\n",
    "|Adjust to changing task needs|Support auto-scaling and dynamic resource allocation|Your company can scale hardware and cloud resource usage for the best performance and lower costs|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30bf82-3af2-45ce-af98-9477cc8b11d7",
   "metadata": {},
   "source": [
    "#### Lecture 5 - Similarity Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553731d7-7b0a-4dbb-b2b4-fc6acd3bdf38",
   "metadata": {},
   "source": [
    "For any two vectors $\\vec{a}$ and $\\vec{b}$ \n",
    "- the **L2 distance** or Eucliendian distance $\\sqrt{\\sum{(a_i-b_i)}^2}$ is a **distance** metric\n",
    "- the **dot product** $\\sum{a_i b_i}$ or $\\lVert{a}\\rVert \\lVert{b}\\rVert cos(\\alpha)$ is a **similarity** metric. However its negative can be used as a distance metric (larger dot product $\\implies$ less distance)\n",
    "- The **cosine similarity** cosine_similarity(a,b) $=\\frac{a . b}{\\lvert{a}\\rVert \\lvert{b}\\rVert} = \\frac{a}{\\lvert{a}\\rVert} \\frac{b}{\\lvert{b}\\rVert} = norm(a) \\times norm(b)$ is a **similarity** metric and (1-cosine_similarity) is a **distance** metric\n",
    "\n",
    "|Metric|Sensitive to Magnitude|Normalised|Best For|\n",
    "|------|------|------|------|\n",
    "|L2 Distance|$\\checkmark$Yes|$\\times$No|Spatial Data, Clustering|\n",
    "|Cosine Distance|$\\times$No|$\\checkmark$Yes|Text, Embeddings, NLP|\n",
    "|Dot Product|$\\checkmark$Yes|$\\times$No|Neural Networks, recommender systems|\n",
    "\n",
    "L2 distance works well for continuous, lower-dimensional data where magnitude matters. \n",
    "\n",
    "Cosine distance excels with high-dimensional, sparse data where direction is more important than magnitude. \n",
    "\n",
    "Dot product offers computational efficiency and is useful when both magnitude and direction contribute to similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25bc29-a8df-40a3-ba4f-6c57e486928a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### Lab on manually implementing Vector Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daca443f-c385-4742-8248-d7d8a9800b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==4.1.0 | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407f0ac-576b-40ab-87b7-c9c166881593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077a691-6a72-4979-be62-a12a475973e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example documents\n",
    "documents = [\n",
    "    'Bugs introduced by the intern had to be squashed by the lead developer.',\n",
    "    'Bugs found by the quality assurance engineer were difficult to debug.',\n",
    "    'Bugs are common throughout the warm summer months, according to the entomologist.',\n",
    "    'Bugs, in particular spiders, are extensively studied by arachnologists.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2124a22-b3cf-4b10-af47-b3aa20d5420e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d621be6-07a2-4eb6-8cb9-c108aa646bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings\n",
    "embeddings = model.encode(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c561d9e5-615a-460a-9d03-48b193ba85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86f2a0-6cbd-4574-a1d4-32a67bd97de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282fa3a1-4918-4aff-91c2-564817bf3598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance_fn(vector1, vector2):\n",
    "    squared_sum = sum((x - y) ** 2 for x, y in zip(vector1, vector2))\n",
    "    return math.sqrt(squared_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede6d57-1b39-465f-9327-fabee654b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance_fn(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cdbc54-4c8b-4195-9e86-eb2e09d49dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_distance_fn(embeddings[1], embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2731e0e7-b754-426f-8a12-2e1819f4805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_manual = np.zeros([4,4])\n",
    "for i in range(embeddings.shape[0]):\n",
    "    for j in range(embeddings.shape[0]):\n",
    "        l2_dist_manual[i,j] = euclidean_distance_fn(embeddings[i], embeddings[j])\n",
    "\n",
    "l2_dist_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7496962c-529c-47c4-a4cc-e6b95d32f0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_manual[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa32ea-50ef-414c-b88c-1f672fbe01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_manual[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5b2e9-eb8d-4189-83d3-72aabfa9aa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_manual_improved = np.zeros([4,4])\n",
    "for i in range(embeddings.shape[0]):\n",
    "    for j in range(embeddings.shape[0]):\n",
    "        if (i>j):\n",
    "            l2_dist_manual_improved[i,j] = l2_dist_manual_improved[j,i]\n",
    "        elif (i<j):\n",
    "            l2_dist_manual_improved[i,j] = euclidean_distance_fn(embeddings[i], embeddings[j])\n",
    "l2_dist_manual_improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f2ee1-d137-49ae-a4c9-13326c512bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist_scipy = scipy.spatial.distance.cdist(embeddings, embeddings, 'euclidean')\n",
    "l2_dist_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55b5437-704e-4300-9eaf-9087fdf40535",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(l2_dist_manual, l2_dist_scipy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6929c27-a10c-4dc2-9acc-c9d43934fccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product_fn(vector1, vector2):\n",
    "    return sum(x * y for x, y in zip(vector1, vector2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c252f7-d2c1-4591-98c3-3ad7b13f6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_fn(embeddings[0], embeddings[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39caefa-2357-492c-85ae-90e293fa66b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_manual = np.empty([4,4])\n",
    "for i in range(embeddings.shape[0]):\n",
    "    for j in range(embeddings.shape[0]):\n",
    "        dot_product_manual[i,j] = dot_product_fn(embeddings[i], embeddings[j])\n",
    "\n",
    "dot_product_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f9a28-29fd-493b-ba19-462c9200f2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication operator\n",
    "dot_product_operator = embeddings @ embeddings.T\n",
    "dot_product_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519e13a-5062-4fb2-9979-5549b377b2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(dot_product_manual, dot_product_operator, atol=1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe18e273-8d84-4a52-bac2-60bd720d4295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to `np.matmul()` if both arrays are 2-D:\n",
    "np.matmul(embeddings,embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa84357-5a4f-4830-8485-4c263ae6ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `np.dot` returns an identical result, but `np.matmul` is recommended if both arrays are 2-D:\n",
    "np.dot(embeddings,embeddings.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3046db09-ee65-4f21-be0d-47299453f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_distance = -dot_product_manual\n",
    "dot_product_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50590bba-f1ad-4fb5-851c-f30f7f9e2099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norms\n",
    "l2_norms = np.sqrt(np.sum(embeddings**2, axis=1))\n",
    "l2_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede00f3-8140-45ba-b027-1f379a3f116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L2 norms reshaped\n",
    "l2_norms_reshaped = l2_norms.reshape(-1,1)\n",
    "l2_norms_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ec045f-d251-45e1-af1b-bec6cf9c5280",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_embeddings_manual = embeddings/l2_norms_reshaped\n",
    "normalized_embeddings_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6c69b-b186-4ef7-8e9b-9f780723a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(np.sqrt(np.sum(normalized_embeddings_manual**2, axis=1)),np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a252dcb-b273-44ec-9190-9b1e17e48c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_embeddings_torch = torch.nn.functional.normalize(\n",
    "    torch.from_numpy(embeddings)\n",
    ").numpy()\n",
    "normalized_embeddings_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955af0ec-d8b1-48ad-b7b5-64637791b3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(normalized_embeddings_manual, normalized_embeddings_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78433ac-adca-4f0c-8665-261edc5c7557",
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_fn(normalized_embeddings_manual[0], normalized_embeddings_manual[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7d3dba-ae77-414f-9fe2-318e6ebd215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_manual = np.empty([4,4])\n",
    "for i in range(normalized_embeddings_manual.shape[0]):\n",
    "    for j in range(normalized_embeddings_manual.shape[0]):\n",
    "        cosine_similarity_manual[i,j] = dot_product_fn(\n",
    "            normalized_embeddings_manual[i], \n",
    "            normalized_embeddings_manual[j]\n",
    "        )\n",
    "\n",
    "cosine_similarity_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614997d2-b370-4533-993c-b227d06e81de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_operator = normalized_embeddings_manual @ normalized_embeddings_manual.T\n",
    "cosine_similarity_operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08151aa0-4816-4bda-9df9-e116a6df5542",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(cosine_similarity_manual, cosine_similarity_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33673e54-9c7c-40dd-a62d-1ce9e932ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - cosine_similarity_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5472d61-d9a8-435f-b592-6fa42f87e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE GOES HERE ###\n",
    "# First, embed the query:\n",
    "query_embedding = model.encode(\n",
    "    [\"Who is responsible for a coding project and fixing others' mistakes?\"]\n",
    ")\n",
    "\n",
    "# Second, normalize the query embedding:\n",
    "normalized_query_embedding = torch.nn.functional.normalize(\n",
    "    torch.from_numpy(query_embedding)\n",
    ").numpy()\n",
    "\n",
    "# Third, calculate the cosine similarity between the documents and the query by using the dot product:\n",
    "cosine_similarity_q3 = normalized_embeddings_manual @ normalized_query_embedding.T\n",
    "\n",
    "# Fourth, find the position of the vector with the highest cosine similarity:\n",
    "highest_cossim_position = cosine_similarity_q3.argmax()\n",
    "\n",
    "# Fifth, find the document in that position in the `documents` array:\n",
    "documents[highest_cossim_position]\n",
    "\n",
    "# As you can see, the query retrieved the document `Bugs introduced by the intern had to be squashed by the lead developer.` which is what we would expect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f730e908-6ad1-4c21-8fba-1d2d7948a89b",
   "metadata": {},
   "source": [
    "#### Lecture 6 - Chroma DB Key Concepts and Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d7cf6-7b4f-4498-9c13-d0adaf2c5df3",
   "metadata": {},
   "source": [
    "**Chroma DB Capabilities**\n",
    "- Storage of embeddings and their metadata\n",
    "- Vector Search\n",
    "- Full-text Search\n",
    "- Document Storage\n",
    "- Metadata Filtering\n",
    "- Multi-Modal Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d8a69-7526-409c-bbc2-827b30a0277d",
   "metadata": {},
   "source": [
    "**Deployment Modes**\n",
    "- *Client Server Architecture*: Client and Server run as independent processes, server is launched through CLI or Docker Image and client connects to server over HTTP\n",
    "- *Standalong Mode*: Meant for Python only, client and server run in same process, useful for capabilities demo or when it is clear that only one machine would be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe8ce73-c464-48ce-ae9c-a68d317d5e86",
   "metadata": {},
   "source": [
    "**Architecture Phases**\n",
    "1. Obtaining Embeddings (Optional, Chroma DB can do this automatically)\n",
    "2. Creating Collections\n",
    "3. Storing Data (need to pass embeddings if Chroma DB is not handling embedding internally)\n",
    "4. Performing Collection Operations (Update/Delete/Rename etc)\n",
    "5. Querying and Grouping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe82edd-7b59-4929-909c-33c87ad32894",
   "metadata": {},
   "source": [
    "**Ecosystem - Clients and Integrations**\n",
    "- Officially supports Python and JS clients. Community supports Java, Ruby, C#, Go, Rust, PHP etc\n",
    "- Integrates with Langchain, LlamaIndex and OLlama\n",
    "- Provides native integrations with HuggingFace, Google and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374cd0f9-2548-4260-b3f4-2834bc2e25a3",
   "metadata": {},
   "source": [
    "**In Practice**\n",
    "Steps to execute\n",
    "1. Create Collection\n",
    "2. Add Text Chunks + Metadata (ChromaDB handles embeddings, else you pass embeddings)\n",
    "3. Query Collection (most similar results returned, query embedding handled internally. Similarity by default is Euclidean (L2) Distance. Dot Product and Cosine Similarity are also supported.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58183bf2-357d-40e3-a0d3-885625ff1ee2",
   "metadata": {},
   "source": [
    "**Performance Features**\n",
    "- Efficient Similarity Search\n",
    "    - Optimized for Nearest Neighbour Search\n",
    "    - Internally uses HNSW Algorithm (Hierarchical Navigable Small World)\n",
    "- Coding Practices\n",
    "    - Written in Rust $\\implies$ 3-5 times improvement in querying and writing ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb2f99-5f7b-4909-b4f6-49481bc96716",
   "metadata": {},
   "source": [
    "**Use Cases and Applications**\n",
    "- Recommender Systems\n",
    "- Document Search with vector or full text search\n",
    "- Image Retrieval, based on text queries using multi-modal retrieval\n",
    "- AI-based chatbots built with semantic search and retrieval capabilities for context augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99e674-f043-4226-a5e5-85fe3cf97a03",
   "metadata": {},
   "source": [
    "**Filtering**\n",
    "- Supports **Metadata filtering** (similar to SQL where clauses but more powerful) and **Document Filtering** (similar to SQL contains clauses but more powerful)\n",
    "- **Metadata Filtering**\n",
    "    - Syntax `collection.get(where={\"key\":\"value\"})` (works for `.delete()`and `.query()`also)\n",
    "    - Following operators are also supported in metadata filtering: `$eq, $ne, $gt, $lt, $gte, $lte, $in, $nin` as `where={\"key\":{\"$eq\":\"value\"}}, where={\"key\":{\"$in\":[\"value1\", \"value2\"]}}` etc\n",
    "\n",
    "    - Filters can be combined as `and`or `or` using the syntax below\n",
    "    ```python\n",
    "    collection.get(\n",
    "        where={\"$and\":[\n",
    "            {\"key1\":{\"$gte\":\"value1\"}}, \n",
    "            {\"key2\":{\"$lt\":\"value2\"}}\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "- **Document Filtering**\n",
    "    - Syntax `collection.get(where_document={\"$contains\":\"value\"})`. `not_contains`is also supported similarly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4bba4d-4e65-4570-a623-ae253564e408",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **Working Example of ChromaDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e447152-ded0-4f08-837a-2306cdc5e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5723c69-2bc1-40fd-ba25-80b11a1bd8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "client=chromadb.Client()\n",
    "\n",
    "collection_name = \"filter_demo\"\n",
    "\n",
    "try:\n",
    "    client.delete_collection(collection_name)\n",
    "except ValueError:\n",
    "    pass\n",
    "\n",
    "collection=client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"description\":\"Used to demo filtering in ChromaDB\"},\n",
    "    configuration={\n",
    "        \"embedding_function\":ef\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Collection Created: {collection.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cc02f-f180-4218-be14-489d17652492",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"This is a document about LangChain\",\n",
    "        \"This is a reading about LlamaIndex\",\n",
    "        \"This is a book about Python\",\n",
    "        \"This is a document about pandas\",\n",
    "        \"This is another document about LangChain\"\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"source\": \"langchain.com\", \"version\": 0.1},\n",
    "        {\"source\": \"llamaindex.ai\", \"version\": 0.2},\n",
    "        {\"source\": \"python.org\", \"version\": 0.3},\n",
    "        {\"source\": \"pandas.pydata.org\", \"version\": 0.4},\n",
    "        {\"source\": \"langchain.com\", \"version\": 0.5},\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5766c345-54d2-4400-bc0b-f52eac2065f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all documents where the source is \"langchain.com\"\n",
    "collection.get(\n",
    "    where={\"source\": {\"$eq\": \"langchain.com\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f309c-bf5a-4520-85fc-c49376938a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finds all documents where the source is \"langchain.com\" with versions less than 0.3\n",
    "collection.get(\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"source\": {\"$eq\": \"langchain.com\"}}, \n",
    "            {\"version\": {\"$lt\": 0.3}}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4545df-3a97-424f-a657-dbd044be7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieves all documents about LangChain and LlamaIndex with a version less than 0.3\n",
    "collection.get(\n",
    "    where={\n",
    "        \"$and\": [\n",
    "            {\"source\": {\"$in\": [\"langchain.com\", \"llamaindex.ai\"]}}, \n",
    "            {\"version\": {\"$lt\": 0.3}}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ddf483-42cb-4db9-991f-f1bfd0cc0d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs a full text search for such documents\n",
    "collection.get(\n",
    "    where_document={\"$contains\":\"pandas\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ebd744-5351-419c-8904-a694ac40fe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks for all documents containing \"LangChain\" or \"Python\" with version numbers greater than 0.1\n",
    "collection.get(\n",
    "    where={\"version\": {\"$gt\": 0.1}},\n",
    "    where_document={\n",
    "        \"$or\": [\n",
    "            {\"$contains\": \"LangChain\"},\n",
    "            {\"$contains\": \"Python\"}\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477ba716-7401-4639-a0a1-4d0a38981c88",
   "metadata": {},
   "source": [
    "##### **Similarity Search and HNSW in Chroma DB**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f01b7-d454-4413-8fd8-f73b1af428e4",
   "metadata": {},
   "source": [
    "**Vector Indexes** are specialized data structures that enable algorithms to compute similarity scores with only a small subset of vectors, significantly speeding up the search while still returning exact or near-optimal results.\n",
    "\n",
    "One such vector index is **Hierarchical Navigable Small World or HNSW**\n",
    "\n",
    "HNSW builds a multi-layered graph where:\n",
    "\n",
    "- The upper layers contain a sparse overview of the data for fast navigation.\n",
    "- The bottom layer holds all vectors for detailed search.\n",
    "\n",
    "Each vector connects to a few nearby neighbors, forming a \"small world\" networkâ€”meaning most vectors can be reached in just a few steps.\n",
    "\n",
    "HNSW is fast, acurate, scaleable, and versatile."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fd7278-faa5-4596-9dd6-d1bf5f60e4ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### **HNSW setup in ChromaDB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c422b125-21c1-404d-afdd-d74661b4ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Collection creation\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection_name = \"hnsw_demo\"\n",
    "\n",
    "try:\n",
    "    client.delete_collection(name=collection_name)\n",
    "except ValueError:\n",
    "    pass\n",
    "    \n",
    "collection = client.create_collection(\n",
    "    name=collection_name,\n",
    "    metadata={\"topic\": \"query testing\"},\n",
    "    configuration={\n",
    "        \"hnsw\": {\n",
    "            # space can be \"l2\" for L2/Euclidean, \"ip\" for inner dot product or \"cosine\" for cosine similarity\n",
    "            \"space\": \"cosine\",\n",
    "            # ef_search determines size of candidate list when nearest neighbour search is done. Higher values\n",
    "            # increase accuracy but reduce speed\n",
    "            \"ef_search\": 100,\n",
    "            # ef_construction determines size of candidate list used to select nearest neighbours when a new \n",
    "            # node is inserted into the index. Again higher values improve accuracy and reduce speed\n",
    "            \"ef_construction\": 100,\n",
    "            # max_neighbors determines maximum connections a node can have during construction. Higher values \n",
    "            # increase accuracy but also increase cost in terms of memory usage and time. Default value is 16\n",
    "            \"max_neighbors\": 16\n",
    "        },\n",
    "        \"embedding_function\": ef\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8275dc-ce47-44ee-b34b-a2294e01d166",
   "metadata": {},
   "source": [
    "Thus `ef_search` affects the breadth of search, while `ef_construction`and `max_neighbours`affect the quality of the vector index built"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d8027-4bb3-4a79-af07-2a926f866260",
   "metadata": {},
   "source": [
    "###### **Querying in Chroma DB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fbf66-d545-464f-bfe7-0388a74d2d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=[\n",
    "        \"Giant pandas are a bear species that lives in mountainous areas.\",\n",
    "        \"A pandas DataFrame stores two-dimensional, tabular data\",\n",
    "        \"I think everyone agrees that pandas are some of the cutest animals on the planet\",\n",
    "        \"A direct comparison between pandas and polars indicates that polars is a more efficient library than pandas.\",\n",
    "    ],\n",
    "    metadatas=[\n",
    "        {\"topic\": \"animals\"},\n",
    "        {\"topic\": \"data analysis\"},\n",
    "        {\"topic\": \"animals\"},\n",
    "        {\"topic\": \"data analysis\"},\n",
    "    ],\n",
    "    ids=[\"id1\", \"id2\", \"id3\", \"id4\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946ae692-b8f7-44f4-a34c-48452fa8556b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will result in all 4 documents to be returned, ordered by increasing distance. \n",
    "collection.query(\n",
    "    query_texts=[\"cat\"],\n",
    "    n_results=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb2c11a-2717-4002-8071-35f09d83f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will falsely fetch the document #4 confusing the polars library with polar bears. \n",
    "collection.query(\n",
    "    query_texts=[\"polar bear\"],\n",
    "    n_results=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11530b7-fe16-4390-84fa-210b3ca8192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be fixed by using filters along with the query as below\n",
    "collection.query(\n",
    "    query_texts=[\"polar bear\"],\n",
    "    n_results=1,\n",
    "    where={'topic': 'animals'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c7d23-c2a1-4842-b8ad-77f3c8db3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as alternative to metadata filtering, we can also use full document text search filter as below\n",
    "collection.query(\n",
    "    query_texts=[\"polar bear\"],\n",
    "    n_results=1,\n",
    "    where_document={'$not_contains': 'library'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a20c5-faaf-4039-a7a8-7af69bb022a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both metadata filtering and full text search can be combined as well, as below\n",
    "collection.query(\n",
    "    query_texts=[\"polar bear\"],\n",
    "    n_results=1,\n",
    "    where={'topic': 'animals'},\n",
    "    where_document={'$not_contains': 'library'}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a01c9-5e4e-4c09-bd28-06d06d0f5562",
   "metadata": {},
   "source": [
    "#### Lab: Similarity Search on Text Using a Chroma Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180e05c6-92dc-4aa4-b543-0bb644fa999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install chromadb==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda91507-e7fa-4033-ace9-1fc62bfca50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==4.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a10f3c-faf8-4b5a-89b0-2d677551c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "# Define the embedding function using SentenceTransformers\n",
    "ef = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed718a8b-d664-4228-8adb-eabf4c2c4d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of ChromaClient to interact with the Chroma DB\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Define the name for the collection to be created or retrieved\n",
    "collection_name = \"my_grocery_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e38180d-2aab-4199-b7a6-056a43d8bdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the main function to interact with the Chroma DB\n",
    "def main():\n",
    "    try:\n",
    "        # Create a collection in the Chroma database with a specified name, \n",
    "        # distance metric, and embedding function. In this case, we are using \n",
    "        # cosine distance\n",
    "        collection = client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"description\": \"A collection for storing grocery data\"},\n",
    "            configuration={\n",
    "                \"hnsw\": {\"space\": \"cosine\"},\n",
    "                \"embedding_function\": ef\n",
    "            }\n",
    "        )\n",
    "        print(f\"Collection created: {collection.name}\")\n",
    "\n",
    "        # Array of grocery-related text items\n",
    "        texts = [\n",
    "            'fresh red apples',\n",
    "            'organic bananas',\n",
    "            'ripe mangoes',\n",
    "            'whole wheat bread',\n",
    "            'farm-fresh eggs',\n",
    "            'natural yogurt',\n",
    "            'frozen vegetables',\n",
    "            'grass-fed beef',\n",
    "            'free-range chicken',\n",
    "            'fresh salmon fillet',\n",
    "            'aromatic coffee beans',\n",
    "            'pure honey',\n",
    "            'golden apple',\n",
    "            'red fruit'\n",
    "        ]\n",
    "        \n",
    "        # Create a list of unique IDs for each text item in the 'texts' array\n",
    "         # Each ID follows the format 'food_<index>', where <index> starts from 1\n",
    "        ids = [f\"food_{index + 1}\" for index, _ in enumerate(texts)]\n",
    "\n",
    "        # Add documents and their corresponding IDs to the collection\n",
    "        # The `add` method inserts the data into the collection\n",
    "        # The documents are the actual text items, and the IDs are unique identifiers\n",
    "        # ChromaDB will automatically generate embeddings using the configured embedding function\n",
    "        collection.add(\n",
    "            documents=texts,\n",
    "            metadatas=[{\"source\": \"grocery_store\", \"category\": \"food\"} for _ in texts],\n",
    "            ids=ids\n",
    "        )\n",
    "\n",
    "        # Retrieve all the items (documents) stored in the collection\n",
    "        # The `get` method fetches all data from the collection\n",
    "        all_items = collection.get()\n",
    "        # Log the retrieved items to the console for inspection\n",
    "        # This will print out all the documents, IDs, and metadata stored in the collection\n",
    "        print(\"Collection contents:\")\n",
    "        print(f\"Number of documents: {len(all_items['documents'])}\")\n",
    "\n",
    "        # Define the query term you want to search for in the collection\n",
    "        query_term = \"apple\"\n",
    "\n",
    "        # Perform a query to search for the most similar documents to the 'query_term'\n",
    "        results = collection.query(\n",
    "            query_texts=[query_term],\n",
    "            n_results=3  # Retrieve top 3 results\n",
    "        )\n",
    "        print(f\"Query results for '{query_term}':\")\n",
    "        print(results)\n",
    "\n",
    "        # Check if no results are returned or if the results array is empty\n",
    "        if not results or not results['ids'] or len(results['ids'][0]) == 0:\n",
    "            # Log a message indicating that no similar documents were found for the query term\n",
    "            print(f'No documents found similar to \"{query_term}\"')\n",
    "            return\n",
    "\n",
    "        print(f'Top 3 similar documents to \"{query_term}\":')\n",
    "        # Access the nested arrays in 'results[\"ids\"]' and 'results[\"distances\"]'\n",
    "        for i in range(min(3, len(results['ids'][0]))):\n",
    "            doc_id = results['ids'][0][i]  # Get ID from 'ids' array\n",
    "            score = results['distances'][0][i]  # Get score from 'distances' array\n",
    "            # Retrieve text data from the results\n",
    "            text = results['documents'][0][i]\n",
    "            if not text:\n",
    "                print(f' - ID: {doc_id}, Text: \"Text not available\", Score: {score:.4f}')\n",
    "            else:\n",
    "                print(f' - ID: {doc_id}, Text: \"{text}\", Score: {score:.4f}')\n",
    "\n",
    "        perform_similarity_search(collection, all_items)\n",
    "        \n",
    "        pass\n",
    "    except Exception as error:  # Catch any errors and log them to the console\n",
    "        print(f\"Error: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50140f-38ee-4d7c-9d4b-ff45b5a1e047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform a similarity search in the collection\n",
    "def perform_similarity_search(collection, all_items):\n",
    "    try:\n",
    "        # Place your similarity search code inside this block\n",
    "        pass\n",
    "    except Exception as error:\n",
    "        print(f\"Error in similarity search: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b4f8d3-b694-4a63-9fad-3d1ed2dfa130",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87d4ef-a7b5-4358-a5d3-816d578567d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
